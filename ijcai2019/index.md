# About

**The 4th International Workshop on Search-Oriented Conversational AI (SCAI)**

at [IJCAI-19](https://www.ijcai19.org/workshops.html), Macao ðŸ‡²ðŸ‡´, China, August 12

**IJCAI early [registration](https://www.ijcai19.org/register.html) is June 20, 2019 (UTC-12)**

> Click [here](https://scai.info) to go to the SCAI main page.

More and more information is found and consumed in a conversational form
rather than using traditional search engines. Chatbots, personal assistants
in our phones and eyes-free devices are being used increasingly more for
different purposes, including information retrieval and exploration. On the
other side, information retrieval empowers dialogue systems to answer
questions and to get context for assisting the user in her tasks.  With the
recent success of deep learning in different areas of natural language
processing, this appears to be the right foundation to power search
conversationalization. Yet, we believe more can be done for theory and
practice of conversation-based search and search-based dialogues.

The aim of this edition of the SCAI workshop is to bring together researchers from the Natural Language Processing (NLP), Artificial Intelligence (AI), and Information Retrieval (IR) communities to investigate future directions of research in the area of search-oriented conversational systems. The focus of this installment seeks to broaden participation between research and industry. The previous instances identified a number of research areas related which warrant additional deeper exploration. To provide a broad forum we solicit a variety of research and position paper submissions. 

The [1st edition](/2017/) of the workshop was co-located with International Conference on the Theory of Information Retrieval (ICTIR 2017).

The [2nd edition](/2018/) of the workshop was co-located with the Conference on Emperical Methods in Natural Language Processing (EMNLP 2018).

The [3rd edition](/www2019/) (special half-day edition) of the workshop was co-located with The Web Conference 2019 (TheWebConf 2019).

## Topics of Interest
   * Surfacing search results or other information in form of a dialogue how to present information coming from search in a form of a dialogue how ensure smooth transition between dialog turns which model to use for dialog-state tracking
   * Evaluation of Search-Oriented Conversational AI â€” From Conversational AI to Personal Assistants
   * Personalization for conversational AI and for its evaluation
   * Deep Learning for Conversational AI
   * (Deep) Reinforcement Learning for Conversational AI
   * Voice as Input (when we consider not only text input, but also voice interactions with the agent â€” how will it affect existing models?)
   * Specialized applications and uses cases for conversational search (specialized domains in health, finance, travel, etc.)

# Important Dates
  * Submission: ~~May 12~~  May 19, 2019
  * Notification: ~~June 2~~  June 5, 2019
  * Camera-ready version: ~~June 16~~  June 19, 2019
  * Workshop: **August 12**

# Workshop Format

- Invited Speakers and Oral Presentation
- Panel Discussion. You can [send](https://app2.sli.do/event/qqcfm2iy/questions) your suggestions.
- Breakout Session to plan a roadmap for Conversational AI
- Poster Session

## Invited Speakers

- [Maarten de Rijke](https://staff.fnwi.uva.nl/m.derijke/activities/), *University of Amsterdam & Innovation Center for Artificial Intelligence*
- [Inho Kang](https://www.linkedin.com/mynetwork/invite-sent/inho-kang-ab29ba117), *Naver Corp*
> - **Title:**  Clova â€“ Leveraging Search Results to make Conversational Agents Smarter
> - **Abstract:** Clova is an AI platform developed by NAVER and LINE. NAVER has been the most popular search engine for over a decade in South Korea, and LINE is the Japan-based global messenger platform.  A smart speaker called Clova Friends that includes Line's free voice-call function and infrared home-appliance control has been launched in Korea and Japan. Clova aims to enable a user to access the relevant information and control devices intuitively and conveniently. NAVER adapts search result ranking based on implicit user feedback to better meet user's needs. One or more search results for the query are key features in guessing the user's intentions. In addition to search technologies such as integrated search and related query suggestion, deep learning-based methods were utilized to understand user's intentions more precisely and improve the accuracy quickly.  In this talk, I will cover some effort and challenge in matching user's intentions to the relevant information, and connecting users based on shared interests to provide the best way to find the information and services. I will introduce the technically challenging problems that we are currently tackling and future AI developments. 
- [Irina Piontkovskaya](https://www.linkedin.com/in/irina-piontkovskaya-6b10b0b5/), *Speech&Dialogs Team, Huawei Noah's Ark Lab*
- [Heming (He Ming) Zhang](https://www.linkedin.com/in/heming-he-ming-zhang-5b7b0386/), *University of Southern California*
- [Abhinav Rastogi](https://www.linkedin.com/in/abhinav-rastogi-0a466934/?originalSubdomain=hr), *Google*
> - **Title:** Towards scalable multi-domain conversational agents
> - **Abstract:** TBD
- [Minlie Huang]([http://coai.cs.tsinghua.edu.cn/hml/](http://coai.cs.tsinghua.edu.cn/hml/)), *Tsinghua University*
> -  **Title:** Towards Building More Intelligent Dialogue Systems: Semantics, Consistency, and Interactiveness
> - **Abstract:** Building open-domain, open-topic dialogue systems (known as chatbot) is one of the most challenging AI tasks due to the difficulties of natural language understanding and the requirements of world knowledge and even semantic reasoning.  The speaker will address three fundamental issues existing in current dialogue systems: semantics, consistency, and interactiveness. As preliminary research attempts to address these problems, the speaker will present some recent studies towards building more intelligent dialogue systems: 1) how a dialogue system can behave more *interactively* via emotion detection and expression, proactive question generation, and sentence function control; 2) how a dialogue system can behave more *consistently* via explicit personalization given a specific profile; and 3) how a dialogue system can behave more *intelligently (semantics)* via using commonsense knowledge for language understanding and generation. These attempts will move forward to more intelligent, human-like chatting machines.
- [Soo-Young Lee]([https://www.linkedin.com/in/soo-young-lee-8b616715/](https://www.linkedin.com/in/soo-young-lee-8b616715/)), *Institute for Artificial Intelligence, School of Electrical Engineering, Brain Science Research Center, Korea Advanced Institute of Science and Technology*
> -  **Title:** Conversational Agents with Emotion and Personality
> - **Abstract:** For the efficient interaction between human and digital companion, i.e., machine agents, the digital companions need to have both human-like emotion and personality. We will start from reporting our continuing efforts and recent results to develop human-like emotional conversational agents as a part of the Korean National Flagship AI Program. The developed emotional conversational agents make emotional dialogue, understand human emotion, and express its own emotion. The emotions of human users are estimated from text, audio, and visual face expression during verbal conversation, and the emotions of intelligent agents are expressed in the speech and facial images. We will first show how our ensemble networks won the Emotion Recognition in the Wild (EmotiW2015) challenge with 61.6% accuracy to recognize seven emotions from facial expression. Then, a multimodal classifier combines text, voice, and facial video for better accuracy. Also, a learning-based Text-to-Speech (TTS) system will be introduced to express emotions in the dialogue. These emotions of human users and agents interact each other during the conversation. Our conversational agents have chitchat and Question-and-Answer (Q&A) modes, and the agents respond differently for different emotional states in chitchat mode. Then, we will discuss our current efforts to incorporate personalities of both human users and conversational agents. Finally, we will further extend the emotions and personality towards minds, i.e., brain internal states, which include trustworthiness, implicit intention, memory, and preference. Since not-much-studies are available, we start from hypotheses on mind space axes and conduct cognitive neuroscience experiments to prove the hypotheses. We believe that this mind model is very important for the efficient interactions and better bindings between human and conversational agents.

## Preliminary Schedule

Session 1 (08:30â€“10:00)

* 08:30â€“08:40 Introduction
* 08:40â€“09:20 **Invited talk 1: Abhinav Rastogi, Google**
* 09:20â€“10:00 **Invited talk 2: Minlie Huang, Tsinghua University**

Session 2 (10:30â€“12:30)
* 10:30â€“11:20 **Invited talk 3: Maarten de Rijke, University of Amsterdam**
* 11:20â€“11:50 Paper presentations 1 (12 min + 3 min Q/A)
> * Rajhans Samdani, Ankit Goyal, Pierre Rappolt and Pratyus Patnaik: [_Practical User Feedback-driven Internal Search Using Online Learning to Rank_](https://arxiv.org/abs/1906.06581)
> * Vishwajeet Kumar, Ganesh Ramakrishnan and Yuan-Fang Li: [_A Framework for Automatic Question Generation from Text using Deep Reinforcement Learning_](https://arxiv.org/abs/1808.04961)
* 11:50â€“12:30 **Invited talk 4: Irina Piontkovskaya, Huawei Noah's Ark Lab**

Session 3 (14:00â€“15:30)
* 14:00â€“14:40 **Invited talk 5: Heming Zhang, University of Southern California**
* 14:40â€“15:10 Paper presentations 2 (12 min + 3 min Q/A)
> * Jiahuan Pei, Arent Stienstra, Julia Kiseleva, and Maarten de Rijke: [_SEntNet: Source-aware Recurrent Entity Networks for Dialogue Response Selection_](https://arxiv.org/abs/1906.06788)
> * Yangjun Zhang, Pengjie Ren and Maarten de Rijke: [_Improving Background Based Conversation with Context-aware Knowledge Pre-selection_](https://arxiv.org/abs/1906.06685)
* 15:10â€“15:30 Poster session (Hall A)

Session 4 (16:00â€“17:30)
* 16:00â€“16:40 **Invited talk 6: Inho Kang, Naver Corp**
* 16:40â€“17:20 **Invited talk 7: Soo-Young Lee, KAIST**
* 17:20â€“18:10 Panel discussion
* 18:10â€“18:15 Closing

## Organizers

  * [Jeff Dalton](http://www.dcs.gla.ac.uk/~jeff/), *University of Glasgow*, Glasgow
  * [Julia Kiseleva](http://juliakiseleva.com), *Microsoft Research & AI*, Seattle
  * [Aleksandr Chuklin](https://www.linkedin.com/in/chuklin/), *Google Research*, ZÃ¼rich
  * [Mikhail Burtsev](https://www.linkedin.com/in/mikhail-burtsev-85a47b9/), *MIPT*, Moscow

# Program Committee
  * Mikhail Arkhipov, *MIPT*
  * OndÅ™ej DuÅ¡ek, *Charles University*
  * Tom Kenter, *Google*
  * Valentin Malykh, *MIPT*
  * Leonid Pugachev, *MIPT*
  * Igor Shalyminov, *Heriot-Watt University*
  * Damiano Spina, *RMIT University*
  * Hamed Zamani, *University of Massachusetts Amherst*

# Questions for Panel Discussion

<iframe src="https://app.sli.do/event/qqcfm2iy" height="600px" width="100%"></iframe>

# Sponsors

## Gold
<a href="https://huawei.com"><img src="media/HuaweiLogo.png" style="max-width: 60%"></a>

<a href="https://microsoft.com"><img src="media/MicrosoftLogo.png" style="max-width: 60%"></a>

## Silver
<a href="https://www.navercorp.com/en"><img src="media/NaverLogo.png" style="max-width: 60%"></a>
## Bronze
<a href="https://google.com"><img src="media/GoogleLogo.png" style="max-width: 60%"></a>
